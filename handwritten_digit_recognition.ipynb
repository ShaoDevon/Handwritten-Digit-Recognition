{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition \n",
    "\n",
    "Training a neural network to recognize hand-written digits from 0-9. \n",
    "\n",
    "## Outline \n",
    "1. Packages \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Packages \n",
    "\n",
    "- [numpy](https://numpy.org/) \n",
    "- [matplotlib](http://matplotlib.org) \n",
    "- [tensorflow](https://www.tensorflow.org/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "#%matplotlib widget\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "#from public_tests import * \n",
    "\n",
    "#from autils import *\n",
    "#from lab_utils_softmax import plt_softmax\n",
    "#np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "X = np.load(\"data/X.npy\")\n",
    "y = np.load(\"data/y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.56059680e-06\n",
      "  1.94035948e-06 -7.37438725e-04 -8.13403799e-03 -1.86104473e-02\n",
      " -1.87412865e-02 -1.87572508e-02 -1.90963542e-02 -1.64039011e-02\n",
      " -3.78191381e-03  3.30347316e-04  1.27655229e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.16421569e-04  1.20052179e-04\n",
      " -1.40444581e-02 -2.84542484e-02  8.03826593e-02  2.66540339e-01\n",
      "  2.73853746e-01  2.78729541e-01  2.74293607e-01  2.24676403e-01\n",
      "  2.77562977e-02 -7.06315478e-03  2.34715414e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.28335523e-17 -3.26286765e-04 -1.38651604e-02\n",
      "  8.15651552e-02  3.82800381e-01  8.57849775e-01  1.00109761e+00\n",
      "  9.69710638e-01  9.30928598e-01  1.00383757e+00  9.64157356e-01\n",
      "  4.49256553e-01 -5.60408259e-03 -3.78319036e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10620915e-06\n",
      "  4.36410675e-04 -3.95509940e-03 -2.68537241e-02  1.00755014e-01\n",
      "  6.42031710e-01  1.03136838e+00  8.50968614e-01  5.43122379e-01\n",
      "  3.42599738e-01  2.68918777e-01  6.68374643e-01  1.01256958e+00\n",
      "  9.03795598e-01  1.04481574e-01 -1.66424973e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.59875260e-05\n",
      " -3.10606987e-03  7.52456076e-03  1.77539831e-01  7.92890120e-01\n",
      "  9.65626503e-01  4.63166079e-01  6.91720680e-02 -3.64100526e-03\n",
      " -4.12180405e-02 -5.01900656e-02  1.56102907e-01  9.01762651e-01\n",
      "  1.04748346e+00  1.51055252e-01 -2.16044665e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.87012352e-05 -6.40931373e-04\n",
      " -3.23305249e-02  2.78203465e-01  9.36720163e-01  1.04320956e+00\n",
      "  5.98003217e-01 -3.59409041e-03 -2.16751770e-02 -4.81021923e-03\n",
      "  6.16566793e-05 -1.23773318e-02  1.55477482e-01  9.14867477e-01\n",
      "  9.20401348e-01  1.09173902e-01 -1.71058007e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.56250000e-04 -4.27724104e-04 -2.51466503e-02\n",
      "  1.30532561e-01  7.81664862e-01  1.02836583e+00  7.57137601e-01\n",
      "  2.84667194e-01  4.86865128e-03 -3.18688725e-03  0.00000000e+00\n",
      "  8.36492601e-04 -3.70751123e-02  4.52644165e-01  1.03180133e+00\n",
      "  5.39028101e-01 -2.43742611e-03 -4.80290033e-03  0.00000000e+00\n",
      "  0.00000000e+00 -7.03635621e-04 -1.27262443e-02  1.61706648e-01\n",
      "  7.79865383e-01  1.03676705e+00  8.04490400e-01  1.60586724e-01\n",
      " -1.38173339e-02  2.14879493e-03 -2.12622549e-04  2.04248366e-04\n",
      " -6.85907627e-03  4.31712963e-04  7.20680947e-01  8.48136063e-01\n",
      "  1.51383408e-01 -2.28404366e-02  1.98971950e-04  0.00000000e+00\n",
      "  0.00000000e+00 -9.40410539e-03  3.74520505e-02  6.94389110e-01\n",
      "  1.02844844e+00  1.01648066e+00  8.80488426e-01  3.92123945e-01\n",
      " -1.74122413e-02 -1.20098039e-04  5.55215142e-05 -2.23907271e-03\n",
      " -2.76068376e-02  3.68645493e-01  9.36411169e-01  4.59006723e-01\n",
      " -4.24701797e-02  1.17356610e-03  1.88929739e-05  0.00000000e+00\n",
      "  0.00000000e+00 -1.93511951e-02  1.29999794e-01  9.79821705e-01\n",
      "  9.41862388e-01  7.75147704e-01  8.73632241e-01  2.12778350e-01\n",
      " -1.72353349e-02  0.00000000e+00  1.09937426e-03 -2.61793751e-02\n",
      "  1.22872879e-01  8.30812662e-01  7.26501773e-01  5.24441863e-02\n",
      " -6.18971913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.36563862e-03  3.68349741e-02  6.99079299e-01\n",
      "  1.00293583e+00  6.05704402e-01  3.27299224e-01 -3.22099249e-02\n",
      " -4.83053002e-02 -4.34069138e-02 -5.75151144e-02  9.55674190e-02\n",
      "  7.26512627e-01  6.95366966e-01  1.47114481e-01 -1.20048679e-02\n",
      " -3.02798203e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.76572712e-04 -6.51415556e-03  1.17339359e-01\n",
      "  4.21948410e-01  9.93210937e-01  8.82013974e-01  7.45758734e-01\n",
      "  7.23874268e-01  7.23341725e-01  7.20020340e-01  8.45324959e-01\n",
      "  8.31859739e-01  6.88831870e-02 -2.77765012e-02  3.59136710e-04\n",
      "  7.14869281e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.53186275e-04  3.17353553e-04 -2.29167177e-02\n",
      " -4.14402914e-03  3.87038450e-01  5.04583435e-01  7.74885876e-01\n",
      "  9.90037446e-01  1.00769478e+00  1.00851440e+00  7.37905042e-01\n",
      "  2.15455291e-01 -2.69624864e-02  1.32506127e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36366422e-04\n",
      " -2.26031454e-03 -2.51994485e-02 -3.73889910e-02  6.62121228e-02\n",
      "  2.91134498e-01  3.23055726e-01  3.06260315e-01  8.76070942e-02\n",
      " -2.50581917e-02  2.37438725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  6.20939216e-18  6.72618320e-04 -1.13151411e-02\n",
      " -3.54641066e-02 -3.88214912e-02 -3.71077412e-02 -1.33524928e-02\n",
      "  9.90964718e-04  4.89176960e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "The first element of y is: 0, the last element of y is 9\n",
      "The shape of X is: (5000, 400), the shape of y is (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check that the dataset loaded properly \n",
    "print(f'The first element of X is: {X[0]}')\n",
    "print(f'The first element of y is: {y[0,0]}, the last element of y is {y[-1,0]}')\n",
    "print(f'The shape of X is: {str(X.shape)}, the shape of y is {str(y.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training, cross validation and test sets \n",
    "X_train, X_, y_train, y_ = train_test_split(X, y, test_size = 0.4)\n",
    "X_crossval, X_test, y_crossval, y_test = train_test_split(X_, y_, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential (\n",
    "    [\n",
    "        tf.keras.layers.InputLayer((400,)),\n",
    "        tf.keras.layers.Dense(25, activation='relu', name='L1'),\n",
    "        tf.keras.layers.Dense(15, activation='relu', name='L2'),\n",
    "        tf.keras.layers.Dense(10, activation='linear', name='L3')\n",
    "    ], name = '3_Layer_model'\n",
    ")\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"3_Layer_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"3_Layer_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,025</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ L1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │        \u001b[38;5;34m10,025\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ L3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,575</span> (41.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,575\u001b[0m (41.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,575</span> (41.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,575\u001b[0m (41.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (400, 25), b1 shape = (25,)\n",
      "W2 shape = (25, 15), b2 shape = (15,)\n",
      "W3 shape = (15, 10), b3 shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - loss: 0.0012 \n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0013\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027    \n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 9.6209e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 6.5251e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 5.3857e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 4.9821e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 5.2135e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 4.6710e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7373e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 4.4317e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0944e-04  \n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8090e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 4.4278e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6307e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 2.8721e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6834e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 2.8451e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 2.5242e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 2.4709e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 2.3076e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 2.0760e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9551e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 2.1626e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 1.7484e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6801e-04  \n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7860e-04  \n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4261e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4865e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 1.3507e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 1.3477e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2681e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1116e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0505e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0707e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0214e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0108e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 8.8679e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6360e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 8.3828e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 8.1640e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 7.4172e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 6.3426e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 6.3067e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 6.1992e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 5.8802e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3261e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4918e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8274e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5085e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 4.3248e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7504e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 4.2237e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5941e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 3.6022e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 3.6190e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 2.8782e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 2.7359e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 2.7951e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 2.5719e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 2.6082e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 2.8394e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 2.3131e-05 \n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 2.1314e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 2.0907e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8469e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 1.7948e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 1.8139e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 1.6239e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 1.5096e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5963e-05 \n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 1.3738e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 1.2901e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 1.2729e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 1.0791e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 1.1976e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8393e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0699e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7563e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5566e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6451e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 8.9764e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 7.4715e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9379e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 6.6806e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 7.3383e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 6.5007e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 6.3603e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 5.5262e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 5.1601e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 5.2129e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 5.1862e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6198e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 4.4471e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 4.3156e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 4.1196e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 3.9918e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 3.6935e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 3.3817e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 3.3206e-06\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mse(y, yhat):\n",
    "    m = len(y) \n",
    "    err = 0.0 \n",
    "    for i in range(m):\n",
    "        err += (y[i] - yhat[i])**2\n",
    "    err /= 2*m\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1600, 10), dtype=float32, numpy=\n",
       "array([[8.4651454e-20, 3.3022693e-32, 2.2439714e-29, ..., 1.0000000e+00,\n",
       "        2.6827940e-22, 7.4957461e-15],\n",
       "       [1.2942257e-21, 7.3018308e-22, 1.1431973e-19, ..., 7.9015767e-23,\n",
       "        1.0759601e-08, 1.0288114e-23],\n",
       "       [8.8363150e-25, 1.3244790e-19, 1.4475929e-18, ..., 7.0486529e-20,\n",
       "        1.3351077e-17, 5.9760226e-13],\n",
       "       ...,\n",
       "       [7.2319884e-26, 8.1186812e-34, 1.0000000e+00, ..., 1.0396370e-23,\n",
       "        1.8665710e-16, 6.0808779e-15],\n",
       "       [3.0452739e-14, 1.7516579e-14, 1.6461367e-17, ..., 4.1601630e-19,\n",
       "        5.2894226e-14, 1.0339750e-12],\n",
       "       [1.7437200e-14, 1.2637465e-06, 9.9678886e-01, ..., 2.5283662e-12,\n",
       "        2.4039545e-03, 1.7041306e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval_preds = model.predict(X_crossval)\n",
    "crossval_preds = tf.nn.softmax(crossval_preds)\n",
    "crossval_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      " predicting a Two: \n",
      "[[-2.6044028   6.332008    7.828155    2.7742958  -5.75013    -2.1812954\n",
      "  -4.7105036  -0.06585044 -1.030035   -1.6532078 ]]\n",
      " Largest Prediction index: 2\n",
      " predicting a Two. Probability vector: \n",
      "[[2.3928915e-05 1.8195204e-01 8.1231672e-01 5.1863543e-03 1.0297957e-06\n",
      "  3.6532227e-05 2.9124290e-06 3.0297201e-04 1.1552131e-04 6.1947190e-05]]\n",
      "Total of predictions: 1.000\n"
     ]
    }
   ],
   "source": [
    "image_of_two = X[1015] # Pull out an entry in the training data set that you know corresponds to an image of a two \n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1,400)) # Use the model to predict a number based on that entry \n",
    "prediction_probs = tf.nn.softmax(prediction) # Use the prediction to identify the probabilities of the entry being each number\n",
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_probs}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_probs):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step\n",
      "13 errors out of 5000 images\n"
     ]
    }
   ],
   "source": [
    "def display_errors(model,X,y):\n",
    "    f = model.predict(X)\n",
    "    yhat = np.argmax(f, axis=1)\n",
    "    doo = yhat != y[:,0]\n",
    "    idxs = np.where(yhat != y[:,0])[0]\n",
    "    return(len(idxs))\n",
    "\n",
    "print(f\"{display_errors(model,X,y)} errors out of {len(X)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
